{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import gdown\n",
    "from matplotlib import pyplot as plt\n",
    "import imageio\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL'\n",
    "# output = 'data.zip'\n",
    "# gdown.download(url, output, quiet=False)\n",
    "# gdown.extractall('data.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_load(path:str) -> List[float]: \n",
    "\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))): \n",
    "        ret, frame = cap.read()\n",
    "        frame = tf.image.rgb_to_grayscale(frame)\n",
    "        frames.append(frame[190:236,80:220,:])\n",
    "    cap.release()\n",
    "    \n",
    "    mean = tf.math.reduce_mean(frames)\n",
    "    std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
    "    return tf.cast((frames - mean), tf.float32) / std\n",
    "    \n",
    "    # mean_image = np.zeros_like(frames[0])\n",
    "    # for frame in frames:\n",
    "    #     mean_image += frame\n",
    "    #     mean_image /= len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is: ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\", '?', '!', '1', '2', '3', '4', '5', '6', '7', '8', '9', ' '] (size =40)\n"
     ]
    }
   ],
   "source": [
    "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
    "num_to_char = tf.keras.layers.StringLookup(vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True)\n",
    "\n",
    "print(f\"The vocabulary is: {char_to_num.get_vocabulary()} \" f\"(size ={char_to_num.vocabulary_size()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignments_load(path:str) -> List[str]:\n",
    "    with open(path, 'r') as f: \n",
    "        lines = f.readlines() \n",
    "    tokens = []\n",
    "    for line in lines:\n",
    "        line = line.split()\n",
    "        if line[2] != 'sil': \n",
    "            tokens = [*tokens,' ',line[2]]\n",
    "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try_path = \"data/s1/bbaf4p.mpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try_path.split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # Get the source and destination folder paths\n",
    "# source_folder_path = \"data/alignments/s1\"\n",
    "# destination_folder_path = \"data/alignments\"\n",
    "\n",
    "# # Get a list of all files in the source folder\n",
    "# files = os.listdir(source_folder_path)\n",
    "\n",
    "# # Iterate over the files and move them to the destination folder\n",
    "# for file in files:\n",
    "#     shutil.move(os.path.join(source_folder_path, file), destination_folder_path)\n",
    "\n",
    "# print(\"All files moved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(path:str):\n",
    "    path_1 = path\n",
    "    path = bytes.decode(path.numpy())\n",
    "    name_file = path.split('/')[-1].split('.')[0]\n",
    "    video_path = path\n",
    "    video_path = \"data/s1/\"+name_file+\".mpg\"\n",
    "    alignments_path = os.path.join('data','alignments',f'{name_file}.align')\n",
    "    frames = video_load(video_path)\n",
    "    alignments = alignments_load(alignments_path)\n",
    "    \n",
    "    return frames, alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, alignments = data_load(tf.convert_to_tensor(try_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mappable_function(path:str) -> List[str]:\n",
    "    result = tf.py_function(data_load,[path],(tf.float32,tf.int64))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(frames[28])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.data.Dataset.list_files(\"./data/s1/*.mpg\")\n",
    "data = data.shuffle(500)\n",
    "data = data.map(mappable_function)\n",
    "data = data.padded_batch(2,padded_shapes=([75,None,None,None],[40]))\n",
    "data = data.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train = data.take(450)\n",
    "test = data.skip(450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames,alignments=data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(frames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = data.as_numpy_iterator()\n",
    "# val = test.next(); val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imageio.mimsave?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imageio.mimsave('./animation.gif',val[0][1],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(val[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.strings.reduce_join([num_to_char(word) for word in val[1][0]])\n",
    "# check=0\n",
    "# sen=\"\"\n",
    "# for word in val[1][0]:\n",
    "#     word = num_to_char(word)\n",
    "#     sen+=word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function = CTC (Connectionist Temporal Classification)\n",
    "# works great for work trascripction which arent aligned to frames, given structure of this model it will repert same letter or word multiple times\n",
    "# CTC reduces duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 46, 140, 1)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.as_numpy_iterator().next()[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv3D(128, 3, input_shape=(75,46,140,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(256, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(75, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Dense(char_to_num.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_12 (Conv3D)          (None, 75, 46, 140, 128   3584      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 75, 46, 140, 128   0         \n",
      "                             )                                   \n",
      "                                                                 \n",
      " max_pooling3d_12 (MaxPooli  (None, 75, 23, 70, 128)   0         \n",
      " ng3D)                                                           \n",
      "                                                                 \n",
      " conv3d_13 (Conv3D)          (None, 75, 23, 70, 256)   884992    \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 75, 23, 70, 256)   0         \n",
      "                                                                 \n",
      " max_pooling3d_13 (MaxPooli  (None, 75, 11, 35, 256)   0         \n",
      " ng3D)                                                           \n",
      "                                                                 \n",
      " conv3d_14 (Conv3D)          (None, 75, 11, 35, 75)    518475    \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 75, 11, 35, 75)    0         \n",
      "                                                                 \n",
      " max_pooling3d_14 (MaxPooli  (None, 75, 5, 17, 75)     0         \n",
      " ng3D)                                                           \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDi  (None, 75, 6375)          0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirecti  (None, 75, 256)           6660096   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 75, 256)           0         \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirecti  (None, 75, 256)           394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 75, 256)           0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 75, 41)            10537     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8471924 (32.32 MB)\n",
      "Trainable params: 8471924 (32.32 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yhat = model.predict(val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sen=\"\"\n",
    "# for word in yhat[0]:\n",
    "#     word = num_to_char(word)\n",
    "#     sen+=word\n",
    "# tf.strings.reduce_join([num_to_char(x) for x in tf.argmax(yhat[0],axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 75, 46, 140, 1)\n",
      "(None, 75, 41)\n"
     ]
    }
   ],
   "source": [
    "print(model.input_shape)\n",
    "print(model.output_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# traing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 30:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTCLoss(y_true, y_pred):\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProduceExample(tf.keras.callbacks.Callback): \n",
    "    def __init__(self, dataset) -> None: \n",
    "        self.dataset = dataset.as_numpy_iterator()\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None) -> None:\n",
    "        data = self.dataset.next()\n",
    "        yhat = self.model.predict(data[0])\n",
    "        decoded = tf.keras.backend.ctc_decode(yhat, [75,75], greedy=False)[0][0].numpy()\n",
    "        for x in range(len(yhat)):           \n",
    "            print('Original:', tf.strings.reduce_join(num_to_char(data[1][x])).numpy().decode('utf-8'))\n",
    "            print('Prediction:', tf.strings.reduce_join(num_to_char(decoded[x])).numpy().decode('utf-8'))\n",
    "            print('~'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss=CTCLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(os.path.join('models','checkpoint'), monitor='loss', save_weights_only=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_callback = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_callback = ProduceExample(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(data, epochs=100, callbacks=[checkpoint_callback, schedule_callback, example_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://drive.google.com/uc?id=1vWscXs4Vt0a_1IH1-ct2TCgXAZT-N3_Y'\n",
    "# output = 'checkpoints.zip'\n",
    "# gdown.download(url, output, quiet=False)\n",
    "# gdown.extractall('checkpoints.zip', 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x29531f790>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('models/checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = test.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x105065930] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x105065930] Warning MVs not available\n"
     ]
    }
   ],
   "source": [
    "# sample = test_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "# yhat = model.predict(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75,75], greedy=True)[0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ REAL TEXT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'bin red in z six now'>,\n",
       " <tf.Tensor: shape=(), dtype=string, numpy=b'set green in o nine again'>]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print('~'*100, 'REAL TEXT')\n",
    "# [tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75,75], greedy=True)[0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PREDICTIONS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'bin red in z six now'>,\n",
       " <tf.Tensor: shape=(), dtype=string, numpy=b'set green in o nine again'>]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print('~'*100, 'PREDICTIONS')\n",
    "# [tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = data_load(tf.convert_to_tensor('./data/s1/bbal8p.mpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ REAL TEXT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'bin blue at l eight please'>]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print('~'*100, 'REAL TEXT')\n",
    "# [tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in [sample[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# yhat = model.predict(tf.expand_dims(sample[0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75], greedy=True)[0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ PREDICTIONS\n",
      "tf.Tensor(b'bin blue at l eight please', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# print('~'*100, 'PREDICTIONS')\n",
    "# [tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_model(path):\n",
    "    a = data_load(path)\n",
    "    yhat = model.predict(tf.expand_dims(a[0], axis=0))\n",
    "    decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75], greedy=True)[0][0].numpy()\n",
    "    # print('~'*100, 'Real')\n",
    "    real = [tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]\n",
    "    # print('~'*100, 'Pridiction')\n",
    "    pridict = [tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]\n",
    "    \n",
    "    return real, pridict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_output(path):\n",
    "    print('~'*100, 'Real')\n",
    "    print(final_model(tf.convert_to_tensor(path))[0])\n",
    "    print('~'*100, 'Pridiction')\n",
    "    print(final_model(tf.convert_to_tensor(path))[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Real\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Real\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Pridiction\n",
      "[<tf.Tensor: shape=(), dtype=string, numpy=b'bin blue at l eight please'>]\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Pridiction\n",
      "1/1 [==============================] - 1s 969ms/step\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Real\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Pridiction\n",
      "[<tf.Tensor: shape=(), dtype=string, numpy=b'bin blue at l eight please'>]\n"
     ]
    }
   ],
   "source": [
    "final_output(\"./data/s1/bbal8p.mpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
